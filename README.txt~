
Tradeoffs, major decisions
1) Sifting through the HTML.
At first, I had an unchecked assumption that HTML was always and necessarily valid XML, as I hadn't given this serious thought in a while, and thus thought it would be a good idea to use an XML parser of some sort (SAX, DOM, etc) I was reminded I was wrong when I encountered tags like <hr>, which didn't necessarily get closed, which no matter what would cause fatal errors in any XML parser.
I then went looking for an HTML parser, that would perhaps be more lax because it would be tailored to HTML and know which tags are allowed what liberties. I happened across jsoup, and was in the process of deciding how best to manage that dependency, when it hit me that these parsers may be overkill. I realized that if I happened across a '<' character, that I did not want characters that followed, until I happened across a '>'. This could be done through a loop through the string. This state, whether to "record" the character or not, is captured in TagFilterer.java and used in PageScraper.java's stripOutTags method. 
2) What is a word?
At first, I would start "recording" as described above when between tags, and replace every non-alphanumeric character I found along the way with a space, making sure that anything separated by a non alpha numeric would be later considered a "word". This was nice I noticed particularly with code that happens to be between tags, like function(){a.getText() would simply become function, a, getText, and the like. But then I started having the problem where things like "can't" would become two words, "can" and "t". I realized that I wanted to interpret a "word" in a human way, as I believe the requirements would want. I then decided that everything between spaces would be a word, but that I would trim them of non-numerics at the beginnings and ends. I'd look for the first and last alphanumeric of the string and take that. This handles words with commas/periods at the end, contractions as discussed, and hyphenated words, but makes a mess of code like "function(){a.getText();b.doOtherThings();c.lastOne". The program could be easily further perfected to not pick up code or filter these out. 
3) A one time use database.
At first when I started solving the database problem, I wanted this to handle multiple pages(I.E. someone using the program to do www.google.com and then later someone launching the program and doing www.yahoo.com). While the application handles this gracefully in its data structure, the database does not.
I did this due to time limitations. A reusable database design does add considerable complexity. Rather than simply insert all words, query for their ids, build their counts, and then insert those, I would have had to build a string like this 'word1', 'word2', inside the code, based on my data structure, so that i can do a "select * from word where word in (" +big_string "). Then, I'd need to build a build insert statement like this INSERT INTO WORDS (name) VALUES ('word1'), ('word2'), but as I built the string I would need to not insert duplicate words, so I'd need to check the list I'd found on the last step before I'd add it to the string. Then, I'd need to collect IDs of all of my words, running some version of the first query again, to get the IDs. Out of that query I'd need to get the words themselves and the IDs, and build counts that way. Perhaps I chose the wrong data structure to build my counts, or I have done something wrong mentally with the data structure but it was starting to take a long time. So the database needs to be cleared between each usage.
Simply executing command sqlite3 scraper.db, and then in the prompt executing delete from word; delete from word_count; will clean out the scraper.db file.
4) Ticks as quotes.
Because I wanted to maintain single ticks for contractions, and I needed to delimit my strings then with double strings, I could not have double strings in the SQL. I replaced those with '`'.
